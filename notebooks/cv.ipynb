{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import mhcflurry, seaborn, numpy, pandas, pickle, sklearn, collections, scipy, time, logging\n",
    "import mhcflurry.data\n",
    "import mhcflurry.imputation\n",
    "import fancyimpute\n",
    "\n",
    "import sklearn.metrics\n",
    "import sklearn.cross_validation\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "min_peptides_to_consider_allele = 50\n",
    "max_ic50 = 50000\n",
    "data_dir = \"/Users/iskander/code/mhcflurry/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(           species         mhc  peptide_length   cv      sequence inequality  \\\n",
       " 0             None      ELA-A1              12  TBD  GSQKLTTGNCNW          =   \n",
       " 1             None      ELA-A1              12  TBD  HVKDETNTTEYW          =   \n",
       " 2             None      ELA-A1              12  TBD  LVEDVTNTAEYW          =   \n",
       " 3             None      ELA-A1              12  TBD  RVEDKTNTAEYW          =   \n",
       " 4             None      ELA-A1              12  TBD  RVEDVKNTAEYW          =   \n",
       " 5             None      ELA-A1              12  TBD  RVEDVTLTAEYW          =   \n",
       " 6             None      ELA-A1              12  TBD  RVEDVTNKAEYW          =   \n",
       " 7             None      ELA-A1              12  TBD  RVEDVTNTAELW          =   \n",
       " 8             None      ELA-A1              12  TBD  RVEDVTNTAEYL          =   \n",
       " 9             None      ELA-A1              12  TBD  RVEDVTNTAEYW          =   \n",
       " 10            None      ELA-A1              12  TBD  RVEDVTNTALYW          =   \n",
       " 11            None      ELA-A1              12  TBD  RVEDVTNTKEYW          =   \n",
       " 12            None      ELA-A1              12  TBD  RVEKVTNTAEYW          =   \n",
       " 13            None      ELA-A1              12  TBD  RVLDVTNTAEYW          =   \n",
       " 14         gorilla  Gogo-B0101              10  TBD    RRFVNVVPTF          =   \n",
       " 15         gorilla  Gogo-B0101               9  TBD     ERYLKDQQL          =   \n",
       " 16         gorilla  Gogo-B0101               9  TBD     GRFKLIVLY          =   \n",
       " 17         gorilla  Gogo-B0101               9  TBD     IDFPKTFGW          =   \n",
       " 18         gorilla  Gogo-B0101               9  TBD     IFFPKTFGW          =   \n",
       " 19         gorilla  Gogo-B0101               9  TBD     IKFPKTFGW          =   \n",
       " 20         gorilla  Gogo-B0101               9  TBD     ILFPKTFGW          =   \n",
       " 21         gorilla  Gogo-B0101               9  TBD     INFPKTFGW          =   \n",
       " 22         gorilla  Gogo-B0101               9  TBD     IRFPKTFGW          =   \n",
       " 23         gorilla  Gogo-B0101               9  TBD     IRYPKTFGW          =   \n",
       " 24         gorilla  Gogo-B0101               9  TBD     KRGILTLKY          =   \n",
       " 25         gorilla  Gogo-B0101               9  TBD     KRKKAYADF          =   \n",
       " 26         gorilla  Gogo-B0101               9  TBD     KRYKSIVKY          =   \n",
       " 27         gorilla  Gogo-B0101               9  TBD     RRYQKSTEL          =   \n",
       " 28         gorilla  Gogo-B0101               9  TBD     SRDKTIIMW          =   \n",
       " 29           mouse      H-2-DB              10  TBD    AAAAAAYAAM          =   \n",
       " ...            ...         ...             ...  ...           ...        ...   \n",
       " 137624  chimpanzee  Patr-B2401               9  TBD     SLYLELDTI          =   \n",
       " 137625  chimpanzee  Patr-B2401               9  TBD     SNYLELDTI          =   \n",
       " 137626  chimpanzee  Patr-B2401               9  TBD     SPYLELDTI          =   \n",
       " 137627  chimpanzee  Patr-B2401               9  TBD     SQYLELDTI          =   \n",
       " 137628  chimpanzee  Patr-B2401               9  TBD     SRYLELDTI          =   \n",
       " 137629  chimpanzee  Patr-B2401               9  TBD     SSYLELDTI          =   \n",
       " 137630  chimpanzee  Patr-B2401               9  TBD     STYLELDTI          =   \n",
       " 137631  chimpanzee  Patr-B2401               9  TBD     SVYLELDTI          =   \n",
       " 137632  chimpanzee  Patr-B2401               9  TBD     SYYLELDTI          =   \n",
       " 137633  chimpanzee  Patr-B2401               9  TBD     TDATSILGI          =   \n",
       " 137634  chimpanzee  Patr-B2401               9  TBD     TDNSSPPAV          =   \n",
       " 137635  chimpanzee  Patr-B2401               9  TBD     TDYLELDTI          =   \n",
       " 137636  chimpanzee  Patr-B2401               9  TBD     TEAMTRYSA          =   \n",
       " 137637  chimpanzee  Patr-B2401               9  TBD     TESTLSTAL          =   \n",
       " 137638  chimpanzee  Patr-B2401               9  TBD     TILGIGTVL          >   \n",
       " 137639  chimpanzee  Patr-B2401               9  TBD     VDFIPVENL          =   \n",
       " 137640  chimpanzee  Patr-B2401               9  TBD     VDILAGYGA          =   \n",
       " 137641  chimpanzee  Patr-B2401               9  TBD     VDKNPHNTA          >   \n",
       " 137642  chimpanzee  Patr-B2401               9  TBD     VDPNIRTGV          >   \n",
       " 137643  chimpanzee  Patr-B2401               9  TBD     VDVQYLYGV          =   \n",
       " 137644  chimpanzee  Patr-B2401               9  TBD     VDYLELDTI          =   \n",
       " 137645  chimpanzee  Patr-B2401               9  TBD     VEAQLHVWV          =   \n",
       " 137646  chimpanzee  Patr-B2401               9  TBD     VESENKVVI          =   \n",
       " 137647  chimpanzee  Patr-B2401               9  TBD     WDQMWKCLI          =   \n",
       " 137648  chimpanzee  Patr-B2401               9  TBD     WEQDLQHGA          =   \n",
       " 137649  chimpanzee  Patr-B2401               9  TBD     WETARHTPV          =   \n",
       " 137650  chimpanzee  Patr-B2401               9  TBD     WEYVVLLFL          =   \n",
       " 137651  chimpanzee  Patr-B2401               9  TBD     YAAQGYKVL          >   \n",
       " 137652  chimpanzee  Patr-B2401               9  TBD     YDVVSKLPL          =   \n",
       " 137653  chimpanzee  Patr-B2401               9  TBD     YVQMALMKL          >   \n",
       " \n",
       "                  meas  regression_output  \n",
       " 0          605.000000           0.408007  \n",
       " 1          880.000000           0.373377  \n",
       " 2          170.000000           0.525332  \n",
       " 3           70.000000           0.607340  \n",
       " 4           65.000000           0.614189  \n",
       " 5          150.000000           0.536900  \n",
       " 6           80.000000           0.594998  \n",
       " 7           25.000000           0.702501  \n",
       " 8           97.000000           0.577190  \n",
       " 9           39.000000           0.661401  \n",
       " 10          78.000000           0.597338  \n",
       " 11          36.000000           0.668799  \n",
       " 12         110.000000           0.565566  \n",
       " 13         520.000000           0.422000  \n",
       " 14         196.000000           0.512179  \n",
       " 15       14579.000000           0.113906  \n",
       " 16        3091.000000           0.257263  \n",
       " 17      107383.000000           0.000000  \n",
       " 18        3174.000000           0.254814  \n",
       " 19        3274.000000           0.251947  \n",
       " 20         998.000000           0.361747  \n",
       " 21       23443.000000           0.070006  \n",
       " 22          30.000000           0.685650  \n",
       " 23          54.000000           0.631325  \n",
       " 24         668.000000           0.398852  \n",
       " 25        6115.000000           0.194207  \n",
       " 26         100.000000           0.574375  \n",
       " 27          53.000000           0.633052  \n",
       " 28         128.000000           0.551559  \n",
       " 29        7333.333333           0.177415  \n",
       " ...               ...                ...  \n",
       " 137624   22409.304697           0.074174  \n",
       " 137625    4803.932379           0.216510  \n",
       " 137626    8210.634469           0.166971  \n",
       " 137627    3841.245189           0.237179  \n",
       " 137628   18216.870451           0.093318  \n",
       " 137629   12389.030549           0.128950  \n",
       " 137630   22995.859278           0.071786  \n",
       " 137631    1504.790451           0.323793  \n",
       " 137632   21620.468423           0.077486  \n",
       " 137633       9.565772           0.791290  \n",
       " 137634      69.913924           0.607454  \n",
       " 137635      12.150058           0.769188  \n",
       " 137636   36866.750907           0.028163  \n",
       " 137637   52196.730666           0.000000  \n",
       " 137638   78125.000000           0.000000  \n",
       " 137639    1304.671425           0.336982  \n",
       " 137640    1529.550065           0.322285  \n",
       " 137641   78125.000000           0.000000  \n",
       " 137642   78125.000000           0.000000  \n",
       " 137643      26.168385           0.698279  \n",
       " 137644       8.751466           0.799513  \n",
       " 137645   11679.657915           0.134400  \n",
       " 137646   12912.904034           0.125122  \n",
       " 137647      45.677950           0.646794  \n",
       " 137648   58495.538057           0.000000  \n",
       " 137649   21366.204458           0.078579  \n",
       " 137650    3422.601957           0.247844  \n",
       " 137651   78125.000000           0.000000  \n",
       " 137652     281.737403           0.478642  \n",
       " 137653   78125.000000           0.000000  \n",
       " \n",
       " [137654 rows x 8 columns], 'sequence')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mhcflurry.data.load_dataframe(\n",
    "        filename=data_dir + \"bdata.2009.mhci.public.1.txt\",\n",
    "        max_ic50=max_ic50,\n",
    "        sep=None,\n",
    "        species_column_name=\"species\",\n",
    "        allele_column_name=\"mhc\",\n",
    "        peptide_column_name=None,\n",
    "        filter_peptide_length=None,\n",
    "        ic50_column_name=\"meas\",\n",
    "        only_human=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_train_data = mhcflurry.data.load_allele_datasets(\n",
    "    data_dir + \"bdata.2009.mhci.public.1.txt\",\n",
    "    use_multiple_peptide_lengths=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alleles = [\n",
    "    \"HLA-A0201\",\n",
    "    # \"HLA-A0301\",\n",
    "    # \"HLA-A0203\",\n",
    "    # \"HLA-A2602\",\n",
    "    # \"HLA-A2603\",\n",
    "    # 'HLA-B7301',\n",
    "]\n",
    "#alleles = alleles[:1] + alleles[-1:]\n",
    "#alleles = [allele for allele in all_train_data if len(all_train_data[allele].Y) >= min_peptides_to_consider_allele]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36749263596306014"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_train_data[alleles[0]].weights.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{8, 9, 10, 11, 12, 13, 14, 15}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(len(x) for x in all_train_data[alleles[0]].original_peptides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{9}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(len(x) for x in all_train_data[alleles[0]].peptides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: 1 / 106 alleles\n"
     ]
    }
   ],
   "source": [
    "#train_data = dict((allele, data)\n",
    "#                  for (allele, data) in all_train_data.items()\n",
    "#                  if len(data.Y) >= min_peptides_to_consider_allele)\n",
    "train_data = dict((allele, all_train_data[allele]) for allele in alleles)\n",
    "print(\"Training data: %d / %d alleles\" % (len(train_data), len(all_train_data)))\n",
    "\n",
    "#test_data = mhcflurry.data.load_allele_datasets(\"/Users/tim/sinai/git/mhcflurry/bdata.2013.mhci.public.blind.1.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def log_to_ic50(log_value):\n",
    "        \"\"\"\n",
    "        Convert neural network output to IC50 values between 0.0 and\n",
    "        self.max_ic50 (typically 5000, 20000 or 50000)\n",
    "        \"\"\"\n",
    "        return max_ic50 ** (1.0 - log_value)\n",
    "\n",
    "def make_scores(y, y_pred, weights=None, sample_weight=None, threshold_nm=500):\n",
    "    ic50_y = log_to_ic50(y)\n",
    "    ic50_y_pred = log_to_ic50(y_pred) \n",
    "    return dict(\n",
    "        auc=sklearn.metrics.roc_auc_score(ic50_y <= threshold_nm, y_pred, sample_weight=sample_weight),\n",
    "        f1=sklearn.metrics.f1_score(ic50_y <= threshold_nm, ic50_y_pred <= threshold_nm, sample_weight=sample_weight),\n",
    "        tau=scipy.stats.kendalltau(y_pred, y)[0],\n",
    "    )    \n",
    "\n",
    "def mean_with_std(grouped_column, decimals=3):\n",
    "    pattern = \"%%0.%df\" % decimals\n",
    "    return pandas.Series([\n",
    "        (pattern + \" +/ \" + pattern) % (m, s) if not pandas.isnull(s) else pattern % m\n",
    "        for (m, s) in zip(grouped_column.mean(), grouped_column.std())\n",
    "    ], index = grouped_column.mean().index)\n",
    "\n",
    "def allele_data_to_df(data):\n",
    "    d = data._asdict()\n",
    "    d[\"X_index\"] = [x for x in d[\"X_index\"]]\n",
    "    d[\"X_binary\"] = [x for x in d[\"X_binary\"]]\n",
    "    df = pandas.DataFrame(d).set_index('peptides')\n",
    "    return df\n",
    "\n",
    "def make_2d_array(thing):\n",
    "    return numpy.array([list(x) for x in thing])\n",
    "\n",
    "def df_to_allele_data(df):\n",
    "    d = dict((col, df[col].values) for col in df)\n",
    "    d[\"X_index\"] = make_2d_array(d[\"X_index\"])\n",
    "    (d[\"max_ic50\"],) = list(df.max_ic50.unique())\n",
    "    return mhcflurry.data.AlleleData(peptides = df.index.values, **d)\n",
    "\n",
    "def get_shuffled_fields(allele_data):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    allele_data : mhcflurry.data.AlleleData\n",
    "    \n",
    "    Returns shuffled array fields\n",
    "    \"\"\"\n",
    "    original_peptides = data.original_peptides\n",
    "    X = data.X_index \n",
    "    Y = data.Y\n",
    "    weights = data.weights\n",
    "    \n",
    "    # shuffle all the  samples!\n",
    "    shuffle_indices = np.arange(len(X))\n",
    "    np.random.shuffle(shuffle_indices)\n",
    "    \n",
    "    X = X[shuffle_indices]\n",
    "    Y = Y[shuffle_indices]\n",
    "    weights = weights[shuffle_indices]\n",
    "    original_peptides = original_peptides[shuffle_indices]\n",
    "    \n",
    "    return X, Y, weights, original_peptides\n",
    "\n",
    "def collapse_9mer_affinities(Y_9mer_true, Y_9mer_pred, original_peptides):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    Y_9mer_true : np.array of float\n",
    "        True regression target values for 9mers extracted from longer/shorter peptides\n",
    "    \n",
    "    Y_9mer_pred : np.array of float\n",
    "        Predicted values for 9mers\n",
    "    \n",
    "    original_peptides : np.array of str\n",
    "        Original peptides of varying length that 9mers were extracted from.\n",
    "    \"\"\"\n",
    "    # collapse multiple 9mer predictions and measured values into \n",
    "    # smaller set of predictions for peptides of varying lengths\n",
    "    peptide_to_true_affinity_dict = defaultdict(list)\n",
    "    peptide_to_predicted_affinity_dict = defaultdict(list)\n",
    "    for i, p in enumerate(original_peptides):\n",
    "        peptide_to_true_affinity_dict[p].append(Y_9mer_true[i])\n",
    "        peptide_to_predicted_affinity_dict[p].append(Y_9mer_pred[i])\n",
    "\n",
    "    unique_peptides = list(sorted(set(peptide_to_predicted_affinity_dict.keys())))\n",
    "    print(\"-- # unique peptides = %d\" % (len(unique_peptides),))\n",
    "    Y_true = np.array([\n",
    "            np.mean(peptide_to_true_affinity_dict[p]) for p in unique_peptides ])\n",
    "    Y_pred = np.array([\n",
    "            np.mean(peptide_to_predicted_affinity_dict[p]) for p in unique_peptides])\n",
    "    return Y_true, Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48 models\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'activation', 'dropout_probability', 'embedding_output_dim', 'layer_sizes'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropout_probabilities = [0.0, 0.1, 0.5]\n",
    "\n",
    "embedding_output_dims = [16, 32, 64, 128]\n",
    "#embedding_output_dims = [4, 32]\n",
    "\n",
    "#layer_sizes = [[4], [8], [16], [64], [128]]\n",
    "layer_sizes_list = [[16], [64], [100], [128]]\n",
    "\n",
    "activations = [\"tanh\"]\n",
    "\n",
    "models_params_list = []\n",
    "for dropout_probability in dropout_probabilities:\n",
    "    for embedding_output_dim in embedding_output_dims:\n",
    "        for layer_sizes in layer_sizes_list:\n",
    "            for activation in activations:\n",
    "                models_params_list.append(dict(\n",
    "                    dropout_probability=dropout_probability,  \n",
    "                    embedding_output_dim=embedding_output_dim,\n",
    "                    layer_sizes=layer_sizes,\n",
    "                    activation=activation))\n",
    "\n",
    "print(\"%d models\" % len(models_params_list))\n",
    "models_params_explored = set.union(*[set(x) for x in models_params_list])\n",
    "models_params_explored\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allele: HLA-A0201\n",
      "-- fold #1/3\n",
      " HLA-A0201 fold   0 [  0 /  48] train_size=21917 test_size=10959 impute=False model={'embedding_output_dim': 16, 'activation': 'tanh', 'layer_sizes': [16], 'dropout_probability': 0.0}\n",
      "-- # unique peptides = 6377\n",
      "-- # unique peptides = 3188\n",
      "train tau: 0.618021\n",
      "train auc: 0.952684\n",
      "train f1: 0.831048\n",
      "test tau: 0.612573\n",
      "test auc: 0.948550\n",
      "test f1: 0.809597\n",
      " HLA-A0201 fold   0 [  1 /  48] train_size=21917 test_size=10959 impute=False model={'embedding_output_dim': 16, 'activation': 'tanh', 'layer_sizes': [64], 'dropout_probability': 0.0}\n",
      "-- # unique peptides = 6377\n",
      "-- # unique peptides = 3188\n",
      "train tau: 0.618157\n",
      "train auc: 0.953468\n",
      "train f1: 0.851550\n",
      "test tau: 0.614993\n",
      "test auc: 0.949692\n",
      "test f1: 0.830500\n",
      " HLA-A0201 fold   0 [  2 /  48] train_size=21917 test_size=10959 impute=False model={'embedding_output_dim': 16, 'activation': 'tanh', 'layer_sizes': [100], 'dropout_probability': 0.0}\n",
      "-- # unique peptides = 6377\n",
      "-- # unique peptides = 3188\n",
      "train tau: 0.617535\n",
      "train auc: 0.952848\n",
      "train f1: 0.845144\n",
      "test tau: 0.613952\n",
      "test auc: 0.948575\n",
      "test f1: 0.824814\n",
      " HLA-A0201 fold   0 [  3 /  48] train_size=21917 test_size=10959 impute=False model={'embedding_output_dim': 16, 'activation': 'tanh', 'layer_sizes': [128], 'dropout_probability': 0.0}\n",
      "-- # unique peptides = 6377\n",
      "-- # unique peptides = 3188\n",
      "train tau: 0.616310\n",
      "train auc: 0.952896\n",
      "train f1: 0.843505\n",
      "test tau: 0.612277\n",
      "test auc: 0.948520\n",
      "test f1: 0.822891\n",
      " HLA-A0201 fold   0 [  4 /  48] train_size=21917 test_size=10959 impute=False model={'embedding_output_dim': 32, 'activation': 'tanh', 'layer_sizes': [16], 'dropout_probability': 0.0}\n",
      "-- # unique peptides = 6377\n",
      "-- # unique peptides = 3188\n",
      "train tau: 0.618374\n",
      "train auc: 0.953687\n",
      "train f1: 0.842508\n",
      "test tau: 0.613897\n",
      "test auc: 0.948914\n",
      "test f1: 0.816873\n",
      " HLA-A0201 fold   0 [  5 /  48] train_size=21917 test_size=10959 impute=False model={'embedding_output_dim': 32, 'activation': 'tanh', 'layer_sizes': [64], 'dropout_probability': 0.0}\n",
      "-- # unique peptides = 6377\n",
      "-- # unique peptides = 3188\n",
      "train tau: 0.617643\n",
      "train auc: 0.953393\n",
      "train f1: 0.831428\n",
      "test tau: 0.612835\n",
      "test auc: 0.949387\n",
      "test f1: 0.815003\n",
      " HLA-A0201 fold   0 [  6 /  48] train_size=21917 test_size=10959 impute=False model={'embedding_output_dim': 32, 'activation': 'tanh', 'layer_sizes': [100], 'dropout_probability': 0.0}\n",
      "-- # unique peptides = 6377\n",
      "-- # unique peptides = 3188\n",
      "train tau: 0.617928\n",
      "train auc: 0.953573\n",
      "train f1: 0.844297\n",
      "test tau: 0.611983\n",
      "test auc: 0.949119\n",
      "test f1: 0.822660\n",
      " HLA-A0201 fold   0 [  7 /  48] train_size=21917 test_size=10959 impute=False model={'embedding_output_dim': 32, 'activation': 'tanh', 'layer_sizes': [128], 'dropout_probability': 0.0}\n",
      "-- # unique peptides = 6377\n",
      "-- # unique peptides = 3188\n",
      "train tau: 0.618311\n",
      "train auc: 0.953679\n",
      "train f1: 0.841121\n",
      "test tau: 0.612928\n",
      "test auc: 0.949277\n",
      "test f1: 0.816286\n",
      " HLA-A0201 fold   0 [  8 /  48] train_size=21917 test_size=10959 impute=False model={'embedding_output_dim': 64, 'activation': 'tanh', 'layer_sizes': [16], 'dropout_probability': 0.0}\n",
      "-- # unique peptides = 6377\n",
      "-- # unique peptides = 3188\n",
      "train tau: 0.620217\n",
      "train auc: 0.953958\n",
      "train f1: 0.842331\n",
      "test tau: 0.614082\n",
      "test auc: 0.949268\n",
      "test f1: 0.823355\n",
      " HLA-A0201 fold   0 [  9 /  48] train_size=21917 test_size=10959 impute=False model={'embedding_output_dim': 64, 'activation': 'tanh', 'layer_sizes': [64], 'dropout_probability': 0.0}\n",
      "-- # unique peptides = 6377\n",
      "-- # unique peptides = 3188\n",
      "train tau: 0.619464\n",
      "train auc: 0.953541\n",
      "train f1: 0.847528\n",
      "test tau: 0.613420\n",
      "test auc: 0.948343\n",
      "test f1: 0.828448\n",
      " HLA-A0201 fold   0 [ 10 /  48] train_size=21917 test_size=10959 impute=False model={'embedding_output_dim': 64, 'activation': 'tanh', 'layer_sizes': [100], 'dropout_probability': 0.0}\n",
      "-- # unique peptides = 6377\n",
      "-- # unique peptides = 3188\n",
      "train tau: 0.620691\n",
      "train auc: 0.953984\n",
      "train f1: 0.844116\n",
      "test tau: 0.614374\n",
      "test auc: 0.949198\n",
      "test f1: 0.819900\n",
      " HLA-A0201 fold   0 [ 11 /  48] train_size=21917 test_size=10959 impute=False model={'embedding_output_dim': 64, 'activation': 'tanh', 'layer_sizes': [128], 'dropout_probability': 0.0}\n",
      "-- # unique peptides = 6377\n",
      "-- # unique peptides = 3188\n",
      "train tau: 0.619349\n",
      "train auc: 0.953555\n",
      "train f1: 0.845143\n",
      "test tau: 0.612461\n",
      "test auc: 0.948535\n",
      "test f1: 0.822957\n",
      " HLA-A0201 fold   0 [ 12 /  48] train_size=21917 test_size=10959 impute=False model={'embedding_output_dim': 128, 'activation': 'tanh', 'layer_sizes': [16], 'dropout_probability': 0.0}\n",
      "-- # unique peptides = 6377\n",
      "-- # unique peptides = 3188\n",
      "train tau: 0.628305\n",
      "train auc: 0.957492\n",
      "train f1: 0.851004\n",
      "test tau: 0.619502\n",
      "test auc: 0.950897\n",
      "test f1: 0.827184\n",
      " HLA-A0201 fold   0 [ 13 /  48] train_size=21917 test_size=10959 impute=False model={'embedding_output_dim': 128, 'activation': 'tanh', 'layer_sizes': [64], 'dropout_probability': 0.0}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-78ae9159f07f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m                 \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights_cv_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m                 n_training_epochs=20)\n\u001b[0m\u001b[1;32m     42\u001b[0m             \u001b[0mfit_time\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/iskander/code/mhcflurry/mhcflurry/class1_binding_predictor.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, Y, sample_weights, X_pretrain, Y_pretrain, sample_weights_pretrain, n_training_epochs, verbose, batch_size)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcombined_weights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_pretrain\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                     \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m                     shuffle=True)\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m    403\u001b[0m                               \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m                               sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight)\u001b[0m\n\u001b[1;32m   1044\u001b[0m                               \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1046\u001b[0;31m                               callback_metrics=callback_metrics)\n\u001b[0m\u001b[1;32m   1047\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, nb_epoch, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics)\u001b[0m\n\u001b[1;32m    788\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 790\u001b[0;31m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    791\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m                 \u001b[0mepoch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_ts_batch_end\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt_before_callbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mdelta_t_median\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_ts_batch_end\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_t_batch\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdelta_t_median\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.95\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_t_batch\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdelta_t_median\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             warnings.warn('Method on_batch_end() is slow compared '\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36mmedian\u001b[0;34m(a, axis, out, overwrite_input, keepdims)\u001b[0m\n\u001b[1;32m   3498\u001b[0m     \"\"\"\n\u001b[1;32m   3499\u001b[0m     r, k = _ureduce(a, func=_median, axis=axis, out=out,\n\u001b[0;32m-> 3500\u001b[0;31m                     overwrite_input=overwrite_input)\n\u001b[0m\u001b[1;32m   3501\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3502\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36m_ureduce\u001b[0;34m(a, func, **kwargs)\u001b[0m\n\u001b[1;32m   3412\u001b[0m         \u001b[0mkeepdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3414\u001b[0;31m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3415\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36m_median\u001b[0;34m(a, axis, out, overwrite_input)\u001b[0m\n\u001b[1;32m   3514\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3515\u001b[0m         \u001b[0msz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3516\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0msz\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3517\u001b[0m         \u001b[0mszh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msz\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3518\u001b[0m         \u001b[0mkth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mszh\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mszh\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "\n",
    "cv_df = defaultdict(list)\n",
    "start = time.time()\n",
    "\n",
    "for (allele, data) in train_data.items():\n",
    "    print(\"Allele: %s\" % allele)\n",
    "    # data_df = allele_data_to_df(data)\n",
    "    X, Y, weights, original_peptides = get_shuffled_fields(data)\n",
    "            \n",
    "    cv = sklearn.cross_validation.LabelKFold(original_peptides, n_folds = 3)\n",
    "    for (fold_num, (train_indices, test_indices)) in enumerate(cv):\n",
    "        print(\"-- fold #%d/3\" % (fold_num + 1,))\n",
    "        X_cv_train = X[train_indices]\n",
    "        X_cv_test = X[test_indices]\n",
    "        \n",
    "        Y_cv_train = Y[train_indices]\n",
    "        Y_cv_test = Y[test_indices]\n",
    "        \n",
    "        weights_cv_train = weights[train_indices]\n",
    "        weights_cv_test = weights[test_indices]\n",
    "        \n",
    "        original_peptides_train = original_peptides[train_indices]\n",
    "        original_peptides_test = original_peptides[test_indices]\n",
    "        \n",
    "        for (i, model_params) in enumerate(models_params_list):\n",
    "            print(\"%10s fold %3d [%3d / %3d] train_size=%d test_size=%d impute=%s model=%s\" %\n",
    "                  (allele, fold_num, i, len(models_params_list), len(train_indices), len(test_indices), impute, model_params))\n",
    "            sys.stdout.flush()\n",
    "            predictor = mhcflurry.Class1BindingPredictor.from_hyperparameters(\n",
    "                max_ic50=max_ic50,\n",
    "                **model_params)\n",
    "\n",
    "            fit_time = -time.time()\n",
    "            predictor.fit(\n",
    "                X_cv_train,\n",
    "                Y_cv_train,\n",
    "                sample_weights=weights_cv_train,\n",
    "                verbose=False,\n",
    "                n_training_epochs=200)\n",
    "            fit_time += time.time()\n",
    "    \n",
    "            Y_cv_train_9mer_predictions = predictor.predict(X_cv_train)\n",
    "            Y_cv_test_9mer_predictions = predictor.predict(X_cv_test)\n",
    "            \n",
    "            Y_train_true, Y_train_pred = collapse_9mer_affinities(\n",
    "                Y_9mer_true=Y_cv_train,\n",
    "                Y_9mer_pred=Y_cv_train_9mer_predictions,\n",
    "                original_peptides=original_peptides_train)\n",
    "            \n",
    "            Y_test_true, Y_test_pred = collapse_9mer_affinities(\n",
    "                Y_9mer_true=Y_cv_test,\n",
    "                Y_9mer_pred=Y_cv_test_9mer_predictions,\n",
    "                original_peptides=original_peptides_test)\n",
    "            \n",
    "            cv_df[\"allele\"].append(allele)\n",
    "            cv_df[\"allele_size\"].append(len(Y))\n",
    "            cv_df[\"train_size\"].append(len(Y_cv_train))\n",
    "            cv_df[\"model_params\"].append(model_params)\n",
    "            cv_df[\"fit_time\"].append(fit_time)\n",
    "\n",
    "            for (param, param_value) in model_params.items():\n",
    "                cv_df[param].append(param_value)\n",
    "            \n",
    "            for (key, value) in make_scores(Y_train_true, Y_train_pred).items():\n",
    "                cv_df[\"train_%s\" % key].append(value)\n",
    "                print(\"train %s: %f\" % (key, value))\n",
    "            \n",
    "            for (key, value) in make_scores(\n",
    "                    Y_test_true, \n",
    "                    Y_test_pred).items():\n",
    "                cv_df[\"test_%s\" % key].append(value)\n",
    "                print(\"test %s: %f\" % (key, value))\n",
    "\n",
    "\n",
    "cv_df = pandas.DataFrame(cv_df)\n",
    "cv_df[\"layer0_size\"] = [x[0] for x in cv_df.layer_sizes]\n",
    "print(time.time() - start)\n",
    "cv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data[\"HLA-A0201\"].X_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cv_df = pandas.DataFrame(cv_df)\n",
    "cv_df[\"layer0_size\"] = [x[0] for x in cv_df.layer_sizes]\n",
    "cv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cv_df.to_csv(\"cv4.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "group_columns = [\"allele\", \"allele_size\", \"impute\"]\n",
    "group_columns.extend(models_params_explored)\n",
    "group_columns.append(\"layer0_size\")\n",
    "group_columns.remove(\"layer_sizes\")\n",
    "print(mean_with_std(cv_df.groupby(group_columns).test_auc)) #.sort(inplace=False, ascending=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def best_by(score):\n",
    "    means = cv_df.groupby(group_columns)[score].mean().reset_index()\n",
    "    max_rows = []\n",
    "    for allele in means.allele.unique():\n",
    "        max_rows.append(means.ix[means.allele == allele][score].argmax())\n",
    "    return means.ix[max_rows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>allele</th>\n",
       "      <th>allele_size</th>\n",
       "      <th>impute</th>\n",
       "      <th>embedding_output_dim</th>\n",
       "      <th>activation</th>\n",
       "      <th>layer0_size</th>\n",
       "      <th>test_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>HLA-A0201</td>\n",
       "      <td>32876</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>tanh</td>\n",
       "      <td>8</td>\n",
       "      <td>0.875208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>HLA-A0203</td>\n",
       "      <td>19879</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>tanh</td>\n",
       "      <td>8</td>\n",
       "      <td>0.828529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>HLA-A0301</td>\n",
       "      <td>19970</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>tanh</td>\n",
       "      <td>4</td>\n",
       "      <td>0.827136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>HLA-A2602</td>\n",
       "      <td>202</td>\n",
       "      <td>False</td>\n",
       "      <td>64</td>\n",
       "      <td>tanh</td>\n",
       "      <td>4</td>\n",
       "      <td>0.960650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>HLA-A2603</td>\n",
       "      <td>205</td>\n",
       "      <td>True</td>\n",
       "      <td>128</td>\n",
       "      <td>tanh</td>\n",
       "      <td>64</td>\n",
       "      <td>0.919985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>HLA-B7301</td>\n",
       "      <td>115</td>\n",
       "      <td>True</td>\n",
       "      <td>32</td>\n",
       "      <td>tanh</td>\n",
       "      <td>8</td>\n",
       "      <td>0.854248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        allele  allele_size impute  embedding_output_dim activation  \\\n",
       "31   HLA-A0201        32876   True                    10       tanh   \n",
       "76   HLA-A0203        19879   True                     5       tanh   \n",
       "125  HLA-A0301        19970   True                     5       tanh   \n",
       "165  HLA-A2602          202  False                    64       tanh   \n",
       "248  HLA-A2603          205   True                   128       tanh   \n",
       "286  HLA-B7301          115   True                    32       tanh   \n",
       "\n",
       "     layer0_size  test_auc  \n",
       "31             8  0.875208  \n",
       "76             8  0.828529  \n",
       "125            4  0.827136  \n",
       "165            4  0.960650  \n",
       "248           64  0.919985  \n",
       "286            8  0.854248  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_by('test_auc')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>allele</th>\n",
       "      <th>allele_size</th>\n",
       "      <th>impute</th>\n",
       "      <th>embedding_output_dim</th>\n",
       "      <th>activation</th>\n",
       "      <th>layer0_size</th>\n",
       "      <th>test_tau</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>HLA-A0201</td>\n",
       "      <td>32876</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>tanh</td>\n",
       "      <td>8</td>\n",
       "      <td>0.508779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>HLA-A0203</td>\n",
       "      <td>19879</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>tanh</td>\n",
       "      <td>4</td>\n",
       "      <td>0.489796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>HLA-A0301</td>\n",
       "      <td>19970</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>tanh</td>\n",
       "      <td>4</td>\n",
       "      <td>0.470644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>HLA-A2602</td>\n",
       "      <td>202</td>\n",
       "      <td>False</td>\n",
       "      <td>32</td>\n",
       "      <td>tanh</td>\n",
       "      <td>8</td>\n",
       "      <td>0.630461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>HLA-A2603</td>\n",
       "      <td>205</td>\n",
       "      <td>True</td>\n",
       "      <td>64</td>\n",
       "      <td>tanh</td>\n",
       "      <td>8</td>\n",
       "      <td>0.391268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>HLA-B7301</td>\n",
       "      <td>115</td>\n",
       "      <td>True</td>\n",
       "      <td>32</td>\n",
       "      <td>tanh</td>\n",
       "      <td>8</td>\n",
       "      <td>0.452451</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        allele  allele_size impute  embedding_output_dim activation  \\\n",
       "31   HLA-A0201        32876   True                    10       tanh   \n",
       "75   HLA-A0203        19879   True                     5       tanh   \n",
       "125  HLA-A0301        19970   True                     5       tanh   \n",
       "161  HLA-A2602          202  False                    32       tanh   \n",
       "241  HLA-A2603          205   True                    64       tanh   \n",
       "286  HLA-B7301          115   True                    32       tanh   \n",
       "\n",
       "     layer0_size  test_tau  \n",
       "31             8  0.508779  \n",
       "75             4  0.489796  \n",
       "125            4  0.470644  \n",
       "161            8  0.630461  \n",
       "241            8  0.391268  \n",
       "286            8  0.452451  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_by('test_tau')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>allele</th>\n",
       "      <th>allele_size</th>\n",
       "      <th>impute</th>\n",
       "      <th>embedding_output_dim</th>\n",
       "      <th>activation</th>\n",
       "      <th>layer0_size</th>\n",
       "      <th>test_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HLA-A0201</td>\n",
       "      <td>32876</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>tanh</td>\n",
       "      <td>4</td>\n",
       "      <td>0.702868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>HLA-A0203</td>\n",
       "      <td>19879</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>tanh</td>\n",
       "      <td>8</td>\n",
       "      <td>0.691566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>HLA-A0301</td>\n",
       "      <td>19970</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>tanh</td>\n",
       "      <td>4</td>\n",
       "      <td>0.645124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>HLA-A2602</td>\n",
       "      <td>202</td>\n",
       "      <td>False</td>\n",
       "      <td>32</td>\n",
       "      <td>tanh</td>\n",
       "      <td>8</td>\n",
       "      <td>0.868255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>HLA-A2603</td>\n",
       "      <td>205</td>\n",
       "      <td>True</td>\n",
       "      <td>128</td>\n",
       "      <td>tanh</td>\n",
       "      <td>64</td>\n",
       "      <td>0.623810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>HLA-B7301</td>\n",
       "      <td>115</td>\n",
       "      <td>False</td>\n",
       "      <td>128</td>\n",
       "      <td>tanh</td>\n",
       "      <td>4</td>\n",
       "      <td>0.321429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        allele  allele_size impute  embedding_output_dim activation  \\\n",
       "0    HLA-A0201        32876  False                     5       tanh   \n",
       "76   HLA-A0203        19879   True                     5       tanh   \n",
       "125  HLA-A0301        19970   True                     5       tanh   \n",
       "161  HLA-A2602          202  False                    32       tanh   \n",
       "248  HLA-A2603          205   True                   128       tanh   \n",
       "270  HLA-B7301          115  False                   128       tanh   \n",
       "\n",
       "     layer0_size   test_f1  \n",
       "0              4  0.702868  \n",
       "76             8  0.691566  \n",
       "125            4  0.645124  \n",
       "161            8  0.868255  \n",
       "248           64  0.623810  \n",
       "270            4  0.321429  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_by('test_f1')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
