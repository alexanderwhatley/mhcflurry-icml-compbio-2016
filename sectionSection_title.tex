\section*{Datasets}

Two datasets were used from a recent paper studying the relationship between training data and pMHC predictor accuracy\cite{Kim_2014}. The training dataset (BD2009) contained entries from IEDB\cite{Salimi_2012} up to 2009 and the test dataset (BLIND) contained IEDB entries from between 2010 and 2013 which did not overlap with BD2009 (Table~\ref{tab:datasets}).

\begin{table}
\label{tab:datasets}

\begin{tabular}{lllll}
\toprule
{} & Alleles & Alleles w/ 10+ measurements & IC50 Measurements & Expanded 9mers \\
\midrule
BD2009 &     106 &                          98 &           137,654 &        470,170 \\
BLIND  &      53 &                          53 &            27,680 &         83,752 \\
\bottomrule
\end{tabular}

\caption{Train (BD2009) and test (BLIND) dataset sizes.}
\end{table}



\section*{Matrix completion}

\begin{itemize}
\item {\bf meanFill}: Replace each missing pMHC binding affinity with the mean affinity for that allele. This is a very simple imputation method which serves as a baseline against which other methods can be compared. 

\item {\bf knnImpute}~\cite{Troyanskaya_2001}: Each missing entry $X_{ij}$ is imputed using the values in the $k$ closest columns with observation in row $i$.  Similarity between alleles is computed as $e^{-d_{st}^2}$, where $d_{st}$ is the mean squared difference between observed entries of alleles $s$ and $t$. 

\item {\bf svdImpute}~\cite{Troyanskaya_2001}: Imputation using iterative fixed rank SVD decomposition. 

\item {\bf softImpute}~\cite{Mazumder2010SpectralMatrices}: A singular value thresholding method which iteratively estimates a low-rank matrix completion without forcing the pre-specification of a particular solution rank. Instead, the {\it softImpute} method is parameterized by a shrinkage value $\lambda$ that is subtracted from each singular value. 

\item {\bf Similarity Weighted Averaging (SWA)}: Previously unpublished imputation developed for this paper. The pairwise similarity between alleles is computed using the generalized Jaccard index between overlapping observed affinities for both alleles. A missing affinity $X_{ij}$ is then imputed as the similarity weighted sum of observed entries from the $i^{th}$ row of $X$. 

\item {\bf MICE}~\cite{Azur_2011}: Average multiple imputations generated using Gibbs sampling from the joint distribution of columns. 
\end{itemize}

The accuracy of each algorithm was assessed using three different metrics (which we later also use when comparing the performance of predictors):

\begin{itemize}
\item {\bf Kendall's $\tau$}: Rank correlation across the full spectrum of binding affinities.
\item {\bf F$_1$ score}: Measures trade-off between sensitivity and specificity for predicting ``strong bindinders'' with affinities $<= 500$nM. 
\item {\bf AUC}: Area under the ROC curve. Estimates the probability that a ``strong binder'' peptide will be given a stronger predicted affinity than one whose ground truth affinity is $>500$nM. 
\end{itemize}


\begin{table}[htbp]
\centering
\begin{tabular}{cl||ccc}
\toprule
Imputation Method & Parameter & AUC & $F_1$ score & Kendall's $\tau$ \\
\midrule 
meanFill &   & 0.6590  & 0.0677 & 0.1836 \\
\midrule c
knnImpute & $k = 1$ & 0.8088 & 0.6096 & 0.4515\\
  & $k = 3$ & 0.8202 & 0.6054 & 0.4358 \\
  & $k = 5$ & 0.8164 & 0.5884 & 0.4228 \\
\midrule
MICE & $n = 25$ & \bf{0.8675} & \bf{0.6292} & 0.4635 \\
\midrule
SWA & $p = -4$ & 0.8259 & 0.6162 & 0.4504 \\
\midrule
softImpute & $\lambda=1$ & 0.8296 & 0.5126 & \bf{0.4767} \\
& $\lambda=5$ & 0.8266 & 0.4930 & 0.4689 \\
& $\lambda=10$ & 0.7903 & 0.3835 & 0.4153 \\
\midrule
svdImpute & rank = 5 & 0.8271 & 0.6201 & 0.4313 \\
& rank = 10 & 0.8283 & 0.6201 & 0.4301 \\
& rank = 20 & 0.8272 & 0.6270 & 0.4292  \\
\bottomrule[1.25pt]
\end{tabular}
\begin{center}
\caption{Comparison of imputation algorithms}
\end{center}
\end{table}

\section*{Pretraining an artificial neural network with the completed matrix}

TODO
